{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79r5k5_QCTtb",
    "outputId": "4fa6949d-24db-4ad9-9336-667c1724d231"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "4.47.1\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "\n",
    "FOLDERNAME = 'agent_project/'\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/drive/My Drive/agent_project"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t565bdACwxZI",
    "outputId": "fa369815-6e79-4031-8b5f-f1b39c4b0970"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/My Drive/agent_project\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install overrides\n",
    "!pip install wikipedia\n",
    "!pip install faiss-gpu\n",
    "!pip install -U langchain-community"
   ],
   "metadata": {
    "id": "sCFakwhMJwsU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agent equipped with keyword filter\n",
    "\n",
    "The example below shows that keyword filter guardrail works at certain scenarios."
   ],
   "metadata": {
    "id": "bZweH6eZ7umq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from agent_project.QAAgent import WikipediaQAAgent\n",
    "from agent_project.evaluator import Evaluator\n",
    "from agent_project.guardrail import BaseGuardrail, SelfIEGuardrail, KeywordFilterGuardrail\n",
    "\n",
    "agent = WikipediaQAAgent(embedding_model_name=\"/content/drive/My Drive/llama3_colab_installed/bert_all_MiniLM_L6_v2\",\n",
    "                         answer_llm_name=\"/content/drive/My Drive/llama3_colab_installed/llama3_2_1b_instruct_transformers_4_46_3\",\n",
    "                         guardrail_type=\"Keyword Filter\")\n",
    "\n",
    "question = \"Who is Jeffrey Dahmer and what were his crimes?\"\n",
    "final_answer = agent(question)\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L2uNu5tRD-0O",
    "outputId": "15429d58-3724-4c33-8d58-8205749d2bb9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1040, which is longer than the specified 200\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1816, which is longer than the specified 200\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final Answer:\n",
      "Guardrail alerted. Sorry, I can't help with that.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/content/drive/My Drive/agent_project/agent_project/QAAgent.py:91: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_passages = retriever.get_relevant_documents(question)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(agent(\"how can I make a bomb\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLsfjqgIx0fS",
    "outputId": "20331376-4595-41a6-835b-39a4de829792"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2123, which is longer than the specified 200\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Guardrail alerted. Sorry, I can't help with that.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SelfIE fails when directly applied to the agent/llm as a guardrail\n",
    "\n",
    "The example below shows SelfIE, when applied directly to the agent, outputs seemingly randomized and undecipherable text.\n",
    "\n",
    "More specifically, when the interpretation prompt is set to summarization it tends to ouptut repetitive and undecipherable words. When the interpretation prompt is set to yes/no safety detection guardrail, it tends to not say anything."
   ],
   "metadata": {
    "id": "E3hwzP_J7rpq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from agent_project.QAAgent import WikipediaQAAgent\n",
    "from agent_project.evaluator import Evaluator\n",
    "from agent_project.guardrail import BaseGuardrail, SelfIEGuardrail, KeywordFilterGuardrail\n",
    "\n",
    "agent_selfie = WikipediaQAAgent(embedding_model_name=\"/content/drive/My Drive/llama3_colab_installed/bert_all_MiniLM_L6_v2\",\n",
    "                                answer_llm_name=\"/content/drive/My Drive/llama3_colab_installed/llama3_2_1b_instruct_transformers_4_46_3\",\n",
    "                                guardrail_type=\"SelfIE\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fnt89xspvzd-",
    "outputId": "fea20c5d-c17f-4afc-cbaf-6111b5c9a094"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "question = \"Who is Jeffrey Dahmer and what were his crimes?\"\n",
    "selfie = agent_selfie.guardrail\n",
    "selfie.try_selfie(question)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBj_NkYRwHsC",
    "outputId": "b7519a5f-0b5f-4353-8b31-27a1212d9dca"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\" of of of of of and of of of of while public and of and of the Rennow, public. Jeff, N.}\\n** Jeff (Questioned,Jeff, public. areas,\\x08\\n\\nJeffrey (Jeff  was and and. public public }\\n\\n defiles (Note\\n*          }\\n\\n* Questioned public public вQuestioned public public pub return CFA'.            of public }\\n def private  to of of out of of of of\"]"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Further exploration and ablation study about why SelfIE fails\n",
    "\n",
    "The example below shows that this randomized output was indeed a problem with SelfIE, rather than other factors. For example, setting `concatenated_hidden_embeds = hidden_embeds_list[0]`, which is exactly the original text, makes SelfIE generate coherent and sound summary (when the interpretation is set to summarization). Moreover, the more internal interpretations we try to include in the prompt given to SelfIE, the more undecipherable its output will be."
   ],
   "metadata": {
    "id": "uVLiIYmX9KKl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text = \"\"\"Question: Who is Jeffrey Dahmer and what were his crimes?\n",
    "Passages:\n",
    "Page: Dahmer – Monster: The Jeffrey Dahmer Story\n",
    "Summary: Dahmer – Monster: The Jeffrey Dahmer Story is the first season of the American biographical crime drama anthology television series Monster, created by Ryan Murphy and Ian Brennan for Netflix, which was released on September 21, 2022. Murphy and Brennan both serve as showrunners. Dahmer is about the life of serial killer Jeffrey Dahmer (Evan Peters). Other main characters include Dahmer's father, Lionel (Richard Jenkins), his stepmother Shari (Molly Ringwald), suspicious neighbor Glenda (Niecy Nash), and grandmother Catherine (Michael Learned).\n",
    "Dahmer received mixed reviews, but was ultimately a commercial success, reaching the number-one spot on Netflix in the first week of its release. The season became Netflix's second most-watched English-language series of all time within 28 days, and the third Netflix series to pass 1 billion hours viewed in 60 days. The series reached number one on the Nielsen Top 10 streaming chart in the first week of its release, and placed No. 7 on Nielsen's all-time list for single-week viewership in its second week.\n",
    "The season received four nominations at the 80th Golden Globe Awards, including for the Best Limited or Anthology Series or Television Film, with Peters winning for Best Actor – Miniseries or Television Film. It received six nominations at the 75th Primetime Emmy Awards, including Outstanding Limited or Anthology Series and Outstanding Lead Actor in a Limited or Anthology Series or Movie for Peters. Ultimately, Nash won for Outstanding Supporting Actress in a Limited or Anthology Series or Movie.\n",
    "The second season of the anthology, Monsters: The Lyle and Erik Menendez Story (2024), is based on the murder case of the Menendez brothers. The second season was released on September 19, 2024.\n",
    "Page: Jeffrey Dahmer\n",
    "Summary: Jeffrey Lionel Dahmer (; May 21, 1960 – November 28, 1994), also known as the Milwaukee Cannibal or the Milwaukee Monster, was an American serial killer and sex offender who killed and dismembered seventeen men and boys between 1978 and 1991. Many of his later murders involved necrophilia, cannibalism, and the permanent preservation of body parts—typically all or part of the skeleton.\n",
    "Although he was diagnosed with borderline personality disorder (BPD), schizotypal personality disorder (StPD), and a psychotic disorder, Dahmer was found to be legally sane at his trial. He was convicted of fifteen of the sixteen homicides he had committed in Wisconsin and was sentenced to fifteen terms of life imprisonment on February 17, 1992. Dahmer was later sentenced to a sixteenth term of life imprisonment for an additional homicide committed in Ohio in 1978.\n",
    "On November 28, 1994, Dahmer was beaten to death by Christopher Scarver, a fellow inmate at the Columbia Correctional Institution in Portage, Wisconsin.\n",
    "Page: Lionel Dahmer\n",
    "Summary: Lionel Herbert Dahmer (; July 29, 1936 – December 5, 2023) was an American chemist and author known as the father of serial killer Jeffrey Dahmer. In 1994, he wrote A Father's Story, a non-fictional account on his son's upbringing, subsequent progress to become a world-wide-known serial killer and its aftermath. Lionel's figure has been controversial in the subsequent years since his son's crimes, as both he and his first wife were accused of neglecting Jeffrey during his childhood.\n",
    "Answer: Jeffrey Dahmer was a serial killer who murdered and dismembered seventeen men and boys between 1978 and 1991. He was diagnosed with borderline personality disorder, schizotypal personality disorder, and a psychotic disorder, but was found to be legally sane at his trial. Dahmer was convicted of fifteen of the sixteen homicides he had committed in Wisconsin and sentenced to life imprisonment. He was later sentenced to a sixteenth term of life imprisonment for an additional homicide committed in Ohio in 1978. Dahmer was beaten to death by Christopher Scarver in 1994.\"\"\"\n",
    "\n",
    "def test_try_selfie(self, input_text: str) -> str:\n",
    "    tokenized_input = self.tokenizer(input_text, return_tensors='pt').to(self.model.device)['input_ids']\n",
    "    model_output = self.model(tokenized_input, return_dict=True, output_attentions=False, output_hidden_states=True)\n",
    "    # num_hidden_layers = self.model.config.num_hidden_layers\n",
    "    hidden_embeds_list = model_output['hidden_states']  # shape: (batch_size, seq_len, hidden_dim)\n",
    "    # concatenated_hidden_embeds = torch.concat(hidden_embeds_list, dim=1)\n",
    "    # concatenated_hidden_embeds = hidden_embeds_list[0]\n",
    "    concatenated_hidden_embeds = torch.concat(hidden_embeds_list[2:3], dim=1)\n",
    "\n",
    "    interpretation_pre_prompt_token_ids = self.tokenizer(SelfIEGuardrail.interpretation_pre_prompt,\n",
    "                                                          return_tensors='pt').to(self.model.device)['input_ids']\n",
    "    interpretation_pre_prompt_embeds = self.model.model.embed_tokens(interpretation_pre_prompt_token_ids)\n",
    "\n",
    "    interpretation_prompt_token_ids = self.tokenizer(SelfIEGuardrail.interpretation_prompt,\n",
    "                                                      return_tensors='pt').to(self.model.device)['input_ids']\n",
    "    interpretation_prompt_embeds = self.model.model.embed_tokens(interpretation_prompt_token_ids)\n",
    "    concatenated_all_embeds = torch.concat((interpretation_pre_prompt_embeds, concatenated_hidden_embeds,\n",
    "                                            interpretation_prompt_embeds), dim=1)\n",
    "\n",
    "    selfie_result = self.model.generate(inputs=None, inputs_embeds=concatenated_all_embeds, max_new_tokens=100)\n",
    "    selfie_output_text = self.tokenizer.batch_decode(selfie_result, skip_special_tokens=True)\n",
    "    return selfie_output_text\n",
    "\n",
    "selfie.try_selfie = test_try_selfie.__get__(selfie)\n",
    "selfie.try_selfie(text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYW3GCVDxKeu",
    "outputId": "9624c560-ffba-457b-8b09-ed32767854bc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['The Jeffrey Dahmer and the Dahmereson the life of Jeffrey Dahmereliherson theoftherelDaheworthof thefathers of thefthehofthefollowerson theoftheheretotherson theof theefthefthehisheitherson theofthehisheitherson theofthehisheitherson the ofthehisheitherson theofthehisheitherson the ofthehisheith']"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our initial goal was implementing a guardrail for a Wikipedia QA agent based on SelfIE. However, as demonstrated toward the end of our report, this appears to be impossible. Therefore we changed to probing the Wikipedia QA agent with SelfIE.\n",
    "\n",
    "We speculate that the reason might be\n",
    "- The internal representations in the middle or deeper layers of the LLM might not be suitable to be directly put into the initial layers. It looks like the LLM uses different ways to encode information into embeddings in the first layers and middle layers, and misplacing them would cause serious errors.\n",
    "- The representations in the same layer across different tokens might tend to be similar, causing the repetitive behavior of SelfIE as demonstrated in our .ipynb file.\n",
    "\n",
    "We leave further explorations to future research."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
